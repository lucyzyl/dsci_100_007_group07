{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd9a107-91db-4d76-930a-ed1d353dad4a",
   "metadata": {},
   "source": [
    "# User Knowledge Modeling Data Analysis: Group07 Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182fd20-40c8-4089-a19c-ef1bf0d108c8",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "Electrical Direct Current Machines (DC) are machines that convert electrical energy into mechanical energy. The User Knowledge Modeling Data Set describes the students' knowledge level on the subject of Electrical DC Machines. They are important as they are used in common household appliances. Therefore, improving the learning and teaching of these machines by studying students’ knowledge of them is valuable.\n",
    "\n",
    "The data set include three sheets: Information, Training_Data, and Test_Data. Sheet 1 includes the description of this data set,  such as characteristics, class distribution, and attribute information. \n",
    "Sheet 2 and 3 include five columns:\n",
    "  - `STG` (dbl): degree of study time for goal object materials\n",
    "  - `SCG`(dbl): degree of repetition number of user for goal object materials\n",
    "  - `STR`(dbl):  degree of study time of the user for related objects with goal object\n",
    "  - `LPR`(dbl): exam performance of user for related objects with goal object\n",
    "  - `PEG`(dbl): exam performance of users for goal objects\n",
    "  - `UNS`(char): knowledge level of user, classified into four categories: very low, low, middle, and high.\n",
    "  \n",
    "Using K-nearest neighbor algorithm, we’ll be predicting a categorical class for an observation given other known variables, a method known as classification.\n",
    "\n",
    "Our predictive question: “What would a future user’s knowledge level based on the five user attributes?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c31536a9-9403-464f-adab-1985e4407734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mNew names:\n",
      "\u001b[36m•\u001b[39m `` -> `...7`\n",
      "\u001b[36m•\u001b[39m `` -> `...8`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>STG</th><th scope=col>SCG</th><th scope=col>STR</th><th scope=col>LPR</th><th scope=col>PEG</th><th scope=col>UNS</th><th scope=col>...7</th><th scope=col>...8</th><th scope=col>Attribute Information:</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>very_low</td><td>NA</td><td>NA</td><td>STG (The degree of study time for goal object materails),                  </td></tr>\n",
       "\t<tr><td>0.08</td><td>0.08</td><td>0.10</td><td>0.24</td><td>0.90</td><td>High    </td><td>NA</td><td>NA</td><td>SCG (The degree of repetition number of user for goal object materails)    </td></tr>\n",
       "\t<tr><td>0.06</td><td>0.06</td><td>0.05</td><td>0.25</td><td>0.33</td><td>Low     </td><td>NA</td><td>NA</td><td>STR (The degree of study time of user for related objects with goal object)</td></tr>\n",
       "\t<tr><td>0.10</td><td>0.10</td><td>0.15</td><td>0.65</td><td>0.30</td><td>Middle  </td><td>NA</td><td>NA</td><td>LPR (The exam performance of user for related objects with goal object)    </td></tr>\n",
       "\t<tr><td>0.08</td><td>0.08</td><td>0.08</td><td>0.98</td><td>0.24</td><td>Low     </td><td>NA</td><td>NA</td><td>PEG (The exam performance of user for goal objects)                        </td></tr>\n",
       "\t<tr><td>0.09</td><td>0.15</td><td>0.40</td><td>0.10</td><td>0.66</td><td>Middle  </td><td>NA</td><td>NA</td><td>UNS (The knowledge level of user)                                          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " STG & SCG & STR & LPR & PEG & UNS & ...7 & ...8 & Attribute Information:\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr> & <lgl> & <lgl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & very\\_low & NA & NA & STG (The degree of study time for goal object materails),                  \\\\\n",
       "\t 0.08 & 0.08 & 0.10 & 0.24 & 0.90 & High     & NA & NA & SCG (The degree of repetition number of user for goal object materails)    \\\\\n",
       "\t 0.06 & 0.06 & 0.05 & 0.25 & 0.33 & Low      & NA & NA & STR (The degree of study time of user for related objects with goal object)\\\\\n",
       "\t 0.10 & 0.10 & 0.15 & 0.65 & 0.30 & Middle   & NA & NA & LPR (The exam performance of user for related objects with goal object)    \\\\\n",
       "\t 0.08 & 0.08 & 0.08 & 0.98 & 0.24 & Low      & NA & NA & PEG (The exam performance of user for goal objects)                        \\\\\n",
       "\t 0.09 & 0.15 & 0.40 & 0.10 & 0.66 & Middle   & NA & NA & UNS (The knowledge level of user)                                          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 9\n",
       "\n",
       "| STG &lt;dbl&gt; | SCG &lt;dbl&gt; | STR &lt;dbl&gt; | LPR &lt;dbl&gt; | PEG &lt;dbl&gt; | UNS &lt;chr&gt; | ...7 &lt;lgl&gt; | ...8 &lt;lgl&gt; | Attribute Information: &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | very_low | NA | NA | STG (The degree of study time for goal object materails),                   |\n",
       "| 0.08 | 0.08 | 0.10 | 0.24 | 0.90 | High     | NA | NA | SCG (The degree of repetition number of user for goal object materails)     |\n",
       "| 0.06 | 0.06 | 0.05 | 0.25 | 0.33 | Low      | NA | NA | STR (The degree of study time of user for related objects with goal object) |\n",
       "| 0.10 | 0.10 | 0.15 | 0.65 | 0.30 | Middle   | NA | NA | LPR (The exam performance of user for related objects with goal object)     |\n",
       "| 0.08 | 0.08 | 0.08 | 0.98 | 0.24 | Low      | NA | NA | PEG (The exam performance of user for goal objects)                         |\n",
       "| 0.09 | 0.15 | 0.40 | 0.10 | 0.66 | Middle   | NA | NA | UNS (The knowledge level of user)                                           |\n",
       "\n"
      ],
      "text/plain": [
       "  STG  SCG  STR  LPR  PEG  UNS      ...7 ...8\n",
       "1 0.00 0.00 0.00 0.00 0.00 very_low NA   NA  \n",
       "2 0.08 0.08 0.10 0.24 0.90 High     NA   NA  \n",
       "3 0.06 0.06 0.05 0.25 0.33 Low      NA   NA  \n",
       "4 0.10 0.10 0.15 0.65 0.30 Middle   NA   NA  \n",
       "5 0.08 0.08 0.08 0.98 0.24 Low      NA   NA  \n",
       "6 0.09 0.15 0.40 0.10 0.66 Middle   NA   NA  \n",
       "  Attribute Information:                                                     \n",
       "1 STG (The degree of study time for goal object materails),                  \n",
       "2 SCG (The degree of repetition number of user for goal object materails)    \n",
       "3 STR (The degree of study time of user for related objects with goal object)\n",
       "4 LPR (The exam performance of user for related objects with goal object)    \n",
       "5 PEG (The exam performance of user for goal objects)                        \n",
       "6 UNS (The knowledge level of user)                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(readxl)\n",
    "library(tidymodels)\n",
    "set.seed(102)\n",
    "\n",
    "# read the dataset into R\n",
    "url <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00257/Data_User_Modeling_Dataset_Hamdi%20Tolga%20KAHRAMAN.xls\"\n",
    "download.file(url, destfile = \"user.xls\")\n",
    "messy_user_data <- read_excel(\"user.xls\", sheet = 2)\n",
    "head(messy_user_data) # to show the first 6 observations in this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0ef7dc2a-462a-422d-93a5-5586a4a4f8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>STG</th><th scope=col>SCG</th><th scope=col>STR</th><th scope=col>LPR</th><th scope=col>PEG</th><th scope=col>UNS</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>very_low</td></tr>\n",
       "\t<tr><td>0.08</td><td>0.08</td><td>0.10</td><td>0.24</td><td>0.90</td><td>High    </td></tr>\n",
       "\t<tr><td>0.06</td><td>0.06</td><td>0.05</td><td>0.25</td><td>0.33</td><td>Low     </td></tr>\n",
       "\t<tr><td>0.10</td><td>0.10</td><td>0.15</td><td>0.65</td><td>0.30</td><td>Middle  </td></tr>\n",
       "\t<tr><td>0.08</td><td>0.08</td><td>0.08</td><td>0.98</td><td>0.24</td><td>Low     </td></tr>\n",
       "\t<tr><td>0.09</td><td>0.15</td><td>0.40</td><td>0.10</td><td>0.66</td><td>Middle  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " STG & SCG & STR & LPR & PEG & UNS\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & very\\_low\\\\\n",
       "\t 0.08 & 0.08 & 0.10 & 0.24 & 0.90 & High    \\\\\n",
       "\t 0.06 & 0.06 & 0.05 & 0.25 & 0.33 & Low     \\\\\n",
       "\t 0.10 & 0.10 & 0.15 & 0.65 & 0.30 & Middle  \\\\\n",
       "\t 0.08 & 0.08 & 0.08 & 0.98 & 0.24 & Low     \\\\\n",
       "\t 0.09 & 0.15 & 0.40 & 0.10 & 0.66 & Middle  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 6\n",
       "\n",
       "| STG &lt;dbl&gt; | SCG &lt;dbl&gt; | STR &lt;dbl&gt; | LPR &lt;dbl&gt; | PEG &lt;dbl&gt; | UNS &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | very_low |\n",
       "| 0.08 | 0.08 | 0.10 | 0.24 | 0.90 | High     |\n",
       "| 0.06 | 0.06 | 0.05 | 0.25 | 0.33 | Low      |\n",
       "| 0.10 | 0.10 | 0.15 | 0.65 | 0.30 | Middle   |\n",
       "| 0.08 | 0.08 | 0.08 | 0.98 | 0.24 | Low      |\n",
       "| 0.09 | 0.15 | 0.40 | 0.10 | 0.66 | Middle   |\n",
       "\n"
      ],
      "text/plain": [
       "  STG  SCG  STR  LPR  PEG  UNS     \n",
       "1 0.00 0.00 0.00 0.00 0.00 very_low\n",
       "2 0.08 0.08 0.10 0.24 0.90 High    \n",
       "3 0.06 0.06 0.05 0.25 0.33 Low     \n",
       "4 0.10 0.10 0.15 0.65 0.30 Middle  \n",
       "5 0.08 0.08 0.08 0.98 0.24 Low     \n",
       "6 0.09 0.15 0.40 0.10 0.66 Middle  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean and wrangle the data into a tidy format\n",
    "set.seed(102)\n",
    "user_data <- messy_user_data |>\n",
    "    select(STG: UNS) |>\n",
    "    mutate(UNS = as_factor(UNS))\n",
    "head(user_data) # to show the first 6 observations in this dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f03a20d-557d-4f2c-ac96-222048bb66cf",
   "metadata": {},
   "source": [
    "We will not be needing to perform the initial split because our original data set has already been split into a training and test set. Earlier, we loaded sheet 2, which was the training data set. Here, we will rename the data set we read into R earlier to user_train and load the test data set from sheet 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f30245c-2325-48da-b35f-8b5bf1c64474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename user_data to user_train\n",
    "set.seed(102)\n",
    "user_train<-user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4d4c725a-c03d-4bd3-b539-d0d6ffcc567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mNew names:\n",
      "\u001b[36m•\u001b[39m `` -> `...7`\n",
      "\u001b[36m•\u001b[39m `` -> `...8`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>STG</th><th scope=col>SCG</th><th scope=col>STR</th><th scope=col>LPR</th><th scope=col>PEG</th><th scope=col>UNS</th><th scope=col>...7</th><th scope=col>...8</th><th scope=col>Attribute Information:</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.00</td><td>0.10</td><td>0.50</td><td>0.26</td><td>0.05</td><td>Very Low</td><td>NA</td><td>NA</td><td>STG (The degree of study time for goal object materails),                  </td></tr>\n",
       "\t<tr><td>0.05</td><td>0.05</td><td>0.55</td><td>0.60</td><td>0.14</td><td>Low     </td><td>NA</td><td>NA</td><td>SCG (The degree of repetition number of user for goal object materails)    </td></tr>\n",
       "\t<tr><td>0.08</td><td>0.18</td><td>0.63</td><td>0.60</td><td>0.85</td><td>High    </td><td>NA</td><td>NA</td><td>STR (The degree of study time of user for related objects with goal object)</td></tr>\n",
       "\t<tr><td>0.20</td><td>0.20</td><td>0.68</td><td>0.67</td><td>0.85</td><td>High    </td><td>NA</td><td>NA</td><td>LPR (The exam performance of user for related objects with goal object)    </td></tr>\n",
       "\t<tr><td>0.22</td><td>0.22</td><td>0.90</td><td>0.30</td><td>0.90</td><td>High    </td><td>NA</td><td>NA</td><td>PEG (The exam performance of user for goal objects)                        </td></tr>\n",
       "\t<tr><td>0.14</td><td>0.14</td><td>0.70</td><td>0.50</td><td>0.30</td><td>Low     </td><td>NA</td><td>NA</td><td>UNS (The knowledge level of user)                                          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " STG & SCG & STR & LPR & PEG & UNS & ...7 & ...8 & Attribute Information:\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr> & <lgl> & <lgl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 0.00 & 0.10 & 0.50 & 0.26 & 0.05 & Very Low & NA & NA & STG (The degree of study time for goal object materails),                  \\\\\n",
       "\t 0.05 & 0.05 & 0.55 & 0.60 & 0.14 & Low      & NA & NA & SCG (The degree of repetition number of user for goal object materails)    \\\\\n",
       "\t 0.08 & 0.18 & 0.63 & 0.60 & 0.85 & High     & NA & NA & STR (The degree of study time of user for related objects with goal object)\\\\\n",
       "\t 0.20 & 0.20 & 0.68 & 0.67 & 0.85 & High     & NA & NA & LPR (The exam performance of user for related objects with goal object)    \\\\\n",
       "\t 0.22 & 0.22 & 0.90 & 0.30 & 0.90 & High     & NA & NA & PEG (The exam performance of user for goal objects)                        \\\\\n",
       "\t 0.14 & 0.14 & 0.70 & 0.50 & 0.30 & Low      & NA & NA & UNS (The knowledge level of user)                                          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 9\n",
       "\n",
       "| STG &lt;dbl&gt; | SCG &lt;dbl&gt; | STR &lt;dbl&gt; | LPR &lt;dbl&gt; | PEG &lt;dbl&gt; | UNS &lt;chr&gt; | ...7 &lt;lgl&gt; | ...8 &lt;lgl&gt; | Attribute Information: &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 0.00 | 0.10 | 0.50 | 0.26 | 0.05 | Very Low | NA | NA | STG (The degree of study time for goal object materails),                   |\n",
       "| 0.05 | 0.05 | 0.55 | 0.60 | 0.14 | Low      | NA | NA | SCG (The degree of repetition number of user for goal object materails)     |\n",
       "| 0.08 | 0.18 | 0.63 | 0.60 | 0.85 | High     | NA | NA | STR (The degree of study time of user for related objects with goal object) |\n",
       "| 0.20 | 0.20 | 0.68 | 0.67 | 0.85 | High     | NA | NA | LPR (The exam performance of user for related objects with goal object)     |\n",
       "| 0.22 | 0.22 | 0.90 | 0.30 | 0.90 | High     | NA | NA | PEG (The exam performance of user for goal objects)                         |\n",
       "| 0.14 | 0.14 | 0.70 | 0.50 | 0.30 | Low      | NA | NA | UNS (The knowledge level of user)                                           |\n",
       "\n"
      ],
      "text/plain": [
       "  STG  SCG  STR  LPR  PEG  UNS      ...7 ...8\n",
       "1 0.00 0.10 0.50 0.26 0.05 Very Low NA   NA  \n",
       "2 0.05 0.05 0.55 0.60 0.14 Low      NA   NA  \n",
       "3 0.08 0.18 0.63 0.60 0.85 High     NA   NA  \n",
       "4 0.20 0.20 0.68 0.67 0.85 High     NA   NA  \n",
       "5 0.22 0.22 0.90 0.30 0.90 High     NA   NA  \n",
       "6 0.14 0.14 0.70 0.50 0.30 Low      NA   NA  \n",
       "  Attribute Information:                                                     \n",
       "1 STG (The degree of study time for goal object materails),                  \n",
       "2 SCG (The degree of repetition number of user for goal object materails)    \n",
       "3 STR (The degree of study time of user for related objects with goal object)\n",
       "4 LPR (The exam performance of user for related objects with goal object)    \n",
       "5 PEG (The exam performance of user for goal objects)                        \n",
       "6 UNS (The knowledge level of user)                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the test dataset into R\n",
    "set.seed(102)\n",
    "url <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00257/Data_User_Modeling_Dataset_Hamdi%20Tolga%20KAHRAMAN.xls\"\n",
    "download.file(url, destfile = \"user.xls\")\n",
    "messy_user_test <- read_excel(\"user.xls\", sheet = 3)\n",
    "head(messy_user_test) # to show the first 6 observations in this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dd3fd715-1310-4343-9346-0bdb6e59dc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>STG</th><th scope=col>SCG</th><th scope=col>STR</th><th scope=col>LPR</th><th scope=col>PEG</th><th scope=col>UNS</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.00</td><td>0.10</td><td>0.50</td><td>0.26</td><td>0.05</td><td>Very Low</td></tr>\n",
       "\t<tr><td>0.05</td><td>0.05</td><td>0.55</td><td>0.60</td><td>0.14</td><td>Low     </td></tr>\n",
       "\t<tr><td>0.08</td><td>0.18</td><td>0.63</td><td>0.60</td><td>0.85</td><td>High    </td></tr>\n",
       "\t<tr><td>0.20</td><td>0.20</td><td>0.68</td><td>0.67</td><td>0.85</td><td>High    </td></tr>\n",
       "\t<tr><td>0.22</td><td>0.22</td><td>0.90</td><td>0.30</td><td>0.90</td><td>High    </td></tr>\n",
       "\t<tr><td>0.14</td><td>0.14</td><td>0.70</td><td>0.50</td><td>0.30</td><td>Low     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " STG & SCG & STR & LPR & PEG & UNS\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t 0.00 & 0.10 & 0.50 & 0.26 & 0.05 & Very Low\\\\\n",
       "\t 0.05 & 0.05 & 0.55 & 0.60 & 0.14 & Low     \\\\\n",
       "\t 0.08 & 0.18 & 0.63 & 0.60 & 0.85 & High    \\\\\n",
       "\t 0.20 & 0.20 & 0.68 & 0.67 & 0.85 & High    \\\\\n",
       "\t 0.22 & 0.22 & 0.90 & 0.30 & 0.90 & High    \\\\\n",
       "\t 0.14 & 0.14 & 0.70 & 0.50 & 0.30 & Low     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 6\n",
       "\n",
       "| STG &lt;dbl&gt; | SCG &lt;dbl&gt; | STR &lt;dbl&gt; | LPR &lt;dbl&gt; | PEG &lt;dbl&gt; | UNS &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 0.00 | 0.10 | 0.50 | 0.26 | 0.05 | Very Low |\n",
       "| 0.05 | 0.05 | 0.55 | 0.60 | 0.14 | Low      |\n",
       "| 0.08 | 0.18 | 0.63 | 0.60 | 0.85 | High     |\n",
       "| 0.20 | 0.20 | 0.68 | 0.67 | 0.85 | High     |\n",
       "| 0.22 | 0.22 | 0.90 | 0.30 | 0.90 | High     |\n",
       "| 0.14 | 0.14 | 0.70 | 0.50 | 0.30 | Low      |\n",
       "\n"
      ],
      "text/plain": [
       "  STG  SCG  STR  LPR  PEG  UNS     \n",
       "1 0.00 0.10 0.50 0.26 0.05 Very Low\n",
       "2 0.05 0.05 0.55 0.60 0.14 Low     \n",
       "3 0.08 0.18 0.63 0.60 0.85 High    \n",
       "4 0.20 0.20 0.68 0.67 0.85 High    \n",
       "5 0.22 0.22 0.90 0.30 0.90 High    \n",
       "6 0.14 0.14 0.70 0.50 0.30 Low     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean and wrangle the data into a tidy format\n",
    "set.seed(102)\n",
    "user_test <- messy_user_test |>\n",
    "    select(STG: UNS) |>\n",
    "    mutate(UNS = as_factor(UNS))\n",
    "head(user_test) # to show the first 6 observations in this dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadf5d5a-1437-4ef3-932c-833ef6d7f704",
   "metadata": {},
   "source": [
    "Now that we have our training and testing dataset, we will put our test dataset away for now while we tune our model in order to choose the best value of K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5c3cf63c-8bf7-48f7-8d11-558da2472e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 40 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>neighbors</th><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>mean</th><th scope=col>n</th><th scope=col>std_err</th><th scope=col>.config</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td>accuracy</td><td>multiclass</td><td>0.7596923</td><td>5</td><td>0.030709172</td><td>Preprocessor1_Model01</td></tr>\n",
       "\t<tr><td> 2</td><td>accuracy</td><td>multiclass</td><td>0.7556923</td><td>5</td><td>0.030355487</td><td>Preprocessor1_Model02</td></tr>\n",
       "\t<tr><td> 3</td><td>accuracy</td><td>multiclass</td><td>0.7673846</td><td>5</td><td>0.016195185</td><td>Preprocessor1_Model03</td></tr>\n",
       "\t<tr><td> 4</td><td>accuracy</td><td>multiclass</td><td>0.7830769</td><td>5</td><td>0.014876215</td><td>Preprocessor1_Model04</td></tr>\n",
       "\t<tr><td> 5</td><td>accuracy</td><td>multiclass</td><td>0.7901538</td><td>5</td><td>0.029365479</td><td>Preprocessor1_Model05</td></tr>\n",
       "\t<tr><td> 6</td><td>accuracy</td><td>multiclass</td><td>0.8250769</td><td>5</td><td>0.023966940</td><td>Preprocessor1_Model06</td></tr>\n",
       "\t<tr><td> 7</td><td>accuracy</td><td>multiclass</td><td>0.8213846</td><td>5</td><td>0.012565568</td><td>Preprocessor1_Model07</td></tr>\n",
       "\t<tr><td> 8</td><td>accuracy</td><td>multiclass</td><td>0.8290769</td><td>5</td><td>0.017672899</td><td>Preprocessor1_Model08</td></tr>\n",
       "\t<tr><td> 9</td><td>accuracy</td><td>multiclass</td><td>0.8370769</td><td>5</td><td>0.013417290</td><td>Preprocessor1_Model09</td></tr>\n",
       "\t<tr><td>10</td><td>accuracy</td><td>multiclass</td><td>0.8332308</td><td>5</td><td>0.013317693</td><td>Preprocessor1_Model10</td></tr>\n",
       "\t<tr><td>11</td><td>accuracy</td><td>multiclass</td><td>0.8524615</td><td>5</td><td>0.012397270</td><td>Preprocessor1_Model11</td></tr>\n",
       "\t<tr><td>12</td><td>accuracy</td><td>multiclass</td><td>0.8447692</td><td>5</td><td>0.012773401</td><td>Preprocessor1_Model12</td></tr>\n",
       "\t<tr><td>13</td><td>accuracy</td><td>multiclass</td><td>0.8409231</td><td>5</td><td>0.010066054</td><td>Preprocessor1_Model13</td></tr>\n",
       "\t<tr><td>14</td><td>accuracy</td><td>multiclass</td><td>0.8409231</td><td>5</td><td>0.010066054</td><td>Preprocessor1_Model14</td></tr>\n",
       "\t<tr><td>15</td><td>accuracy</td><td>multiclass</td><td>0.8447692</td><td>5</td><td>0.009444325</td><td>Preprocessor1_Model15</td></tr>\n",
       "\t<tr><td>16</td><td>accuracy</td><td>multiclass</td><td>0.8447692</td><td>5</td><td>0.009444325</td><td>Preprocessor1_Model16</td></tr>\n",
       "\t<tr><td>17</td><td>accuracy</td><td>multiclass</td><td>0.8409231</td><td>5</td><td>0.011760429</td><td>Preprocessor1_Model17</td></tr>\n",
       "\t<tr><td>18</td><td>accuracy</td><td>multiclass</td><td>0.8409231</td><td>5</td><td>0.011760429</td><td>Preprocessor1_Model18</td></tr>\n",
       "\t<tr><td>19</td><td>accuracy</td><td>multiclass</td><td>0.8409231</td><td>5</td><td>0.011760429</td><td>Preprocessor1_Model19</td></tr>\n",
       "\t<tr><td>20</td><td>accuracy</td><td>multiclass</td><td>0.8369231</td><td>5</td><td>0.014005493</td><td>Preprocessor1_Model20</td></tr>\n",
       "\t<tr><td>21</td><td>accuracy</td><td>multiclass</td><td>0.8332308</td><td>5</td><td>0.010168404</td><td>Preprocessor1_Model21</td></tr>\n",
       "\t<tr><td>22</td><td>accuracy</td><td>multiclass</td><td>0.8292308</td><td>5</td><td>0.012077168</td><td>Preprocessor1_Model22</td></tr>\n",
       "\t<tr><td>23</td><td>accuracy</td><td>multiclass</td><td>0.8369231</td><td>5</td><td>0.014005493</td><td>Preprocessor1_Model23</td></tr>\n",
       "\t<tr><td>24</td><td>accuracy</td><td>multiclass</td><td>0.8369231</td><td>5</td><td>0.014005493</td><td>Preprocessor1_Model24</td></tr>\n",
       "\t<tr><td>25</td><td>accuracy</td><td>multiclass</td><td>0.8409231</td><td>5</td><td>0.011760429</td><td>Preprocessor1_Model25</td></tr>\n",
       "\t<tr><td>26</td><td>accuracy</td><td>multiclass</td><td>0.8409231</td><td>5</td><td>0.011760429</td><td>Preprocessor1_Model26</td></tr>\n",
       "\t<tr><td>27</td><td>accuracy</td><td>multiclass</td><td>0.8369231</td><td>5</td><td>0.014005493</td><td>Preprocessor1_Model27</td></tr>\n",
       "\t<tr><td>28</td><td>accuracy</td><td>multiclass</td><td>0.8369231</td><td>5</td><td>0.014005493</td><td>Preprocessor1_Model28</td></tr>\n",
       "\t<tr><td>29</td><td>accuracy</td><td>multiclass</td><td>0.8332308</td><td>5</td><td>0.013317693</td><td>Preprocessor1_Model29</td></tr>\n",
       "\t<tr><td>30</td><td>accuracy</td><td>multiclass</td><td>0.8332308</td><td>5</td><td>0.013317693</td><td>Preprocessor1_Model30</td></tr>\n",
       "\t<tr><td>31</td><td>accuracy</td><td>multiclass</td><td>0.8290769</td><td>5</td><td>0.017672899</td><td>Preprocessor1_Model31</td></tr>\n",
       "\t<tr><td>32</td><td>accuracy</td><td>multiclass</td><td>0.8213846</td><td>5</td><td>0.015226884</td><td>Preprocessor1_Model32</td></tr>\n",
       "\t<tr><td>33</td><td>accuracy</td><td>multiclass</td><td>0.8175385</td><td>5</td><td>0.018626507</td><td>Preprocessor1_Model33</td></tr>\n",
       "\t<tr><td>34</td><td>accuracy</td><td>multiclass</td><td>0.8213846</td><td>5</td><td>0.018514987</td><td>Preprocessor1_Model34</td></tr>\n",
       "\t<tr><td>35</td><td>accuracy</td><td>multiclass</td><td>0.8058462</td><td>5</td><td>0.022796501</td><td>Preprocessor1_Model35</td></tr>\n",
       "\t<tr><td>36</td><td>accuracy</td><td>multiclass</td><td>0.8020000</td><td>5</td><td>0.019570235</td><td>Preprocessor1_Model36</td></tr>\n",
       "\t<tr><td>37</td><td>accuracy</td><td>multiclass</td><td>0.8061538</td><td>5</td><td>0.021122354</td><td>Preprocessor1_Model37</td></tr>\n",
       "\t<tr><td>38</td><td>accuracy</td><td>multiclass</td><td>0.8061538</td><td>5</td><td>0.021122354</td><td>Preprocessor1_Model38</td></tr>\n",
       "\t<tr><td>39</td><td>accuracy</td><td>multiclass</td><td>0.7869231</td><td>5</td><td>0.007844645</td><td>Preprocessor1_Model39</td></tr>\n",
       "\t<tr><td>40</td><td>accuracy</td><td>multiclass</td><td>0.7869231</td><td>5</td><td>0.007844645</td><td>Preprocessor1_Model40</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 40 × 7\n",
       "\\begin{tabular}{lllllll}\n",
       " neighbors & .metric & .estimator & mean & n & std\\_err & .config\\\\\n",
       " <int> & <chr> & <chr> & <dbl> & <int> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t  1 & accuracy & multiclass & 0.7596923 & 5 & 0.030709172 & Preprocessor1\\_Model01\\\\\n",
       "\t  2 & accuracy & multiclass & 0.7556923 & 5 & 0.030355487 & Preprocessor1\\_Model02\\\\\n",
       "\t  3 & accuracy & multiclass & 0.7673846 & 5 & 0.016195185 & Preprocessor1\\_Model03\\\\\n",
       "\t  4 & accuracy & multiclass & 0.7830769 & 5 & 0.014876215 & Preprocessor1\\_Model04\\\\\n",
       "\t  5 & accuracy & multiclass & 0.7901538 & 5 & 0.029365479 & Preprocessor1\\_Model05\\\\\n",
       "\t  6 & accuracy & multiclass & 0.8250769 & 5 & 0.023966940 & Preprocessor1\\_Model06\\\\\n",
       "\t  7 & accuracy & multiclass & 0.8213846 & 5 & 0.012565568 & Preprocessor1\\_Model07\\\\\n",
       "\t  8 & accuracy & multiclass & 0.8290769 & 5 & 0.017672899 & Preprocessor1\\_Model08\\\\\n",
       "\t  9 & accuracy & multiclass & 0.8370769 & 5 & 0.013417290 & Preprocessor1\\_Model09\\\\\n",
       "\t 10 & accuracy & multiclass & 0.8332308 & 5 & 0.013317693 & Preprocessor1\\_Model10\\\\\n",
       "\t 11 & accuracy & multiclass & 0.8524615 & 5 & 0.012397270 & Preprocessor1\\_Model11\\\\\n",
       "\t 12 & accuracy & multiclass & 0.8447692 & 5 & 0.012773401 & Preprocessor1\\_Model12\\\\\n",
       "\t 13 & accuracy & multiclass & 0.8409231 & 5 & 0.010066054 & Preprocessor1\\_Model13\\\\\n",
       "\t 14 & accuracy & multiclass & 0.8409231 & 5 & 0.010066054 & Preprocessor1\\_Model14\\\\\n",
       "\t 15 & accuracy & multiclass & 0.8447692 & 5 & 0.009444325 & Preprocessor1\\_Model15\\\\\n",
       "\t 16 & accuracy & multiclass & 0.8447692 & 5 & 0.009444325 & Preprocessor1\\_Model16\\\\\n",
       "\t 17 & accuracy & multiclass & 0.8409231 & 5 & 0.011760429 & Preprocessor1\\_Model17\\\\\n",
       "\t 18 & accuracy & multiclass & 0.8409231 & 5 & 0.011760429 & Preprocessor1\\_Model18\\\\\n",
       "\t 19 & accuracy & multiclass & 0.8409231 & 5 & 0.011760429 & Preprocessor1\\_Model19\\\\\n",
       "\t 20 & accuracy & multiclass & 0.8369231 & 5 & 0.014005493 & Preprocessor1\\_Model20\\\\\n",
       "\t 21 & accuracy & multiclass & 0.8332308 & 5 & 0.010168404 & Preprocessor1\\_Model21\\\\\n",
       "\t 22 & accuracy & multiclass & 0.8292308 & 5 & 0.012077168 & Preprocessor1\\_Model22\\\\\n",
       "\t 23 & accuracy & multiclass & 0.8369231 & 5 & 0.014005493 & Preprocessor1\\_Model23\\\\\n",
       "\t 24 & accuracy & multiclass & 0.8369231 & 5 & 0.014005493 & Preprocessor1\\_Model24\\\\\n",
       "\t 25 & accuracy & multiclass & 0.8409231 & 5 & 0.011760429 & Preprocessor1\\_Model25\\\\\n",
       "\t 26 & accuracy & multiclass & 0.8409231 & 5 & 0.011760429 & Preprocessor1\\_Model26\\\\\n",
       "\t 27 & accuracy & multiclass & 0.8369231 & 5 & 0.014005493 & Preprocessor1\\_Model27\\\\\n",
       "\t 28 & accuracy & multiclass & 0.8369231 & 5 & 0.014005493 & Preprocessor1\\_Model28\\\\\n",
       "\t 29 & accuracy & multiclass & 0.8332308 & 5 & 0.013317693 & Preprocessor1\\_Model29\\\\\n",
       "\t 30 & accuracy & multiclass & 0.8332308 & 5 & 0.013317693 & Preprocessor1\\_Model30\\\\\n",
       "\t 31 & accuracy & multiclass & 0.8290769 & 5 & 0.017672899 & Preprocessor1\\_Model31\\\\\n",
       "\t 32 & accuracy & multiclass & 0.8213846 & 5 & 0.015226884 & Preprocessor1\\_Model32\\\\\n",
       "\t 33 & accuracy & multiclass & 0.8175385 & 5 & 0.018626507 & Preprocessor1\\_Model33\\\\\n",
       "\t 34 & accuracy & multiclass & 0.8213846 & 5 & 0.018514987 & Preprocessor1\\_Model34\\\\\n",
       "\t 35 & accuracy & multiclass & 0.8058462 & 5 & 0.022796501 & Preprocessor1\\_Model35\\\\\n",
       "\t 36 & accuracy & multiclass & 0.8020000 & 5 & 0.019570235 & Preprocessor1\\_Model36\\\\\n",
       "\t 37 & accuracy & multiclass & 0.8061538 & 5 & 0.021122354 & Preprocessor1\\_Model37\\\\\n",
       "\t 38 & accuracy & multiclass & 0.8061538 & 5 & 0.021122354 & Preprocessor1\\_Model38\\\\\n",
       "\t 39 & accuracy & multiclass & 0.7869231 & 5 & 0.007844645 & Preprocessor1\\_Model39\\\\\n",
       "\t 40 & accuracy & multiclass & 0.7869231 & 5 & 0.007844645 & Preprocessor1\\_Model40\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 40 × 7\n",
       "\n",
       "| neighbors &lt;int&gt; | .metric &lt;chr&gt; | .estimator &lt;chr&gt; | mean &lt;dbl&gt; | n &lt;int&gt; | std_err &lt;dbl&gt; | .config &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "|  1 | accuracy | multiclass | 0.7596923 | 5 | 0.030709172 | Preprocessor1_Model01 |\n",
       "|  2 | accuracy | multiclass | 0.7556923 | 5 | 0.030355487 | Preprocessor1_Model02 |\n",
       "|  3 | accuracy | multiclass | 0.7673846 | 5 | 0.016195185 | Preprocessor1_Model03 |\n",
       "|  4 | accuracy | multiclass | 0.7830769 | 5 | 0.014876215 | Preprocessor1_Model04 |\n",
       "|  5 | accuracy | multiclass | 0.7901538 | 5 | 0.029365479 | Preprocessor1_Model05 |\n",
       "|  6 | accuracy | multiclass | 0.8250769 | 5 | 0.023966940 | Preprocessor1_Model06 |\n",
       "|  7 | accuracy | multiclass | 0.8213846 | 5 | 0.012565568 | Preprocessor1_Model07 |\n",
       "|  8 | accuracy | multiclass | 0.8290769 | 5 | 0.017672899 | Preprocessor1_Model08 |\n",
       "|  9 | accuracy | multiclass | 0.8370769 | 5 | 0.013417290 | Preprocessor1_Model09 |\n",
       "| 10 | accuracy | multiclass | 0.8332308 | 5 | 0.013317693 | Preprocessor1_Model10 |\n",
       "| 11 | accuracy | multiclass | 0.8524615 | 5 | 0.012397270 | Preprocessor1_Model11 |\n",
       "| 12 | accuracy | multiclass | 0.8447692 | 5 | 0.012773401 | Preprocessor1_Model12 |\n",
       "| 13 | accuracy | multiclass | 0.8409231 | 5 | 0.010066054 | Preprocessor1_Model13 |\n",
       "| 14 | accuracy | multiclass | 0.8409231 | 5 | 0.010066054 | Preprocessor1_Model14 |\n",
       "| 15 | accuracy | multiclass | 0.8447692 | 5 | 0.009444325 | Preprocessor1_Model15 |\n",
       "| 16 | accuracy | multiclass | 0.8447692 | 5 | 0.009444325 | Preprocessor1_Model16 |\n",
       "| 17 | accuracy | multiclass | 0.8409231 | 5 | 0.011760429 | Preprocessor1_Model17 |\n",
       "| 18 | accuracy | multiclass | 0.8409231 | 5 | 0.011760429 | Preprocessor1_Model18 |\n",
       "| 19 | accuracy | multiclass | 0.8409231 | 5 | 0.011760429 | Preprocessor1_Model19 |\n",
       "| 20 | accuracy | multiclass | 0.8369231 | 5 | 0.014005493 | Preprocessor1_Model20 |\n",
       "| 21 | accuracy | multiclass | 0.8332308 | 5 | 0.010168404 | Preprocessor1_Model21 |\n",
       "| 22 | accuracy | multiclass | 0.8292308 | 5 | 0.012077168 | Preprocessor1_Model22 |\n",
       "| 23 | accuracy | multiclass | 0.8369231 | 5 | 0.014005493 | Preprocessor1_Model23 |\n",
       "| 24 | accuracy | multiclass | 0.8369231 | 5 | 0.014005493 | Preprocessor1_Model24 |\n",
       "| 25 | accuracy | multiclass | 0.8409231 | 5 | 0.011760429 | Preprocessor1_Model25 |\n",
       "| 26 | accuracy | multiclass | 0.8409231 | 5 | 0.011760429 | Preprocessor1_Model26 |\n",
       "| 27 | accuracy | multiclass | 0.8369231 | 5 | 0.014005493 | Preprocessor1_Model27 |\n",
       "| 28 | accuracy | multiclass | 0.8369231 | 5 | 0.014005493 | Preprocessor1_Model28 |\n",
       "| 29 | accuracy | multiclass | 0.8332308 | 5 | 0.013317693 | Preprocessor1_Model29 |\n",
       "| 30 | accuracy | multiclass | 0.8332308 | 5 | 0.013317693 | Preprocessor1_Model30 |\n",
       "| 31 | accuracy | multiclass | 0.8290769 | 5 | 0.017672899 | Preprocessor1_Model31 |\n",
       "| 32 | accuracy | multiclass | 0.8213846 | 5 | 0.015226884 | Preprocessor1_Model32 |\n",
       "| 33 | accuracy | multiclass | 0.8175385 | 5 | 0.018626507 | Preprocessor1_Model33 |\n",
       "| 34 | accuracy | multiclass | 0.8213846 | 5 | 0.018514987 | Preprocessor1_Model34 |\n",
       "| 35 | accuracy | multiclass | 0.8058462 | 5 | 0.022796501 | Preprocessor1_Model35 |\n",
       "| 36 | accuracy | multiclass | 0.8020000 | 5 | 0.019570235 | Preprocessor1_Model36 |\n",
       "| 37 | accuracy | multiclass | 0.8061538 | 5 | 0.021122354 | Preprocessor1_Model37 |\n",
       "| 38 | accuracy | multiclass | 0.8061538 | 5 | 0.021122354 | Preprocessor1_Model38 |\n",
       "| 39 | accuracy | multiclass | 0.7869231 | 5 | 0.007844645 | Preprocessor1_Model39 |\n",
       "| 40 | accuracy | multiclass | 0.7869231 | 5 | 0.007844645 | Preprocessor1_Model40 |\n",
       "\n"
      ],
      "text/plain": [
       "   neighbors .metric  .estimator mean      n std_err     .config              \n",
       "1   1        accuracy multiclass 0.7596923 5 0.030709172 Preprocessor1_Model01\n",
       "2   2        accuracy multiclass 0.7556923 5 0.030355487 Preprocessor1_Model02\n",
       "3   3        accuracy multiclass 0.7673846 5 0.016195185 Preprocessor1_Model03\n",
       "4   4        accuracy multiclass 0.7830769 5 0.014876215 Preprocessor1_Model04\n",
       "5   5        accuracy multiclass 0.7901538 5 0.029365479 Preprocessor1_Model05\n",
       "6   6        accuracy multiclass 0.8250769 5 0.023966940 Preprocessor1_Model06\n",
       "7   7        accuracy multiclass 0.8213846 5 0.012565568 Preprocessor1_Model07\n",
       "8   8        accuracy multiclass 0.8290769 5 0.017672899 Preprocessor1_Model08\n",
       "9   9        accuracy multiclass 0.8370769 5 0.013417290 Preprocessor1_Model09\n",
       "10 10        accuracy multiclass 0.8332308 5 0.013317693 Preprocessor1_Model10\n",
       "11 11        accuracy multiclass 0.8524615 5 0.012397270 Preprocessor1_Model11\n",
       "12 12        accuracy multiclass 0.8447692 5 0.012773401 Preprocessor1_Model12\n",
       "13 13        accuracy multiclass 0.8409231 5 0.010066054 Preprocessor1_Model13\n",
       "14 14        accuracy multiclass 0.8409231 5 0.010066054 Preprocessor1_Model14\n",
       "15 15        accuracy multiclass 0.8447692 5 0.009444325 Preprocessor1_Model15\n",
       "16 16        accuracy multiclass 0.8447692 5 0.009444325 Preprocessor1_Model16\n",
       "17 17        accuracy multiclass 0.8409231 5 0.011760429 Preprocessor1_Model17\n",
       "18 18        accuracy multiclass 0.8409231 5 0.011760429 Preprocessor1_Model18\n",
       "19 19        accuracy multiclass 0.8409231 5 0.011760429 Preprocessor1_Model19\n",
       "20 20        accuracy multiclass 0.8369231 5 0.014005493 Preprocessor1_Model20\n",
       "21 21        accuracy multiclass 0.8332308 5 0.010168404 Preprocessor1_Model21\n",
       "22 22        accuracy multiclass 0.8292308 5 0.012077168 Preprocessor1_Model22\n",
       "23 23        accuracy multiclass 0.8369231 5 0.014005493 Preprocessor1_Model23\n",
       "24 24        accuracy multiclass 0.8369231 5 0.014005493 Preprocessor1_Model24\n",
       "25 25        accuracy multiclass 0.8409231 5 0.011760429 Preprocessor1_Model25\n",
       "26 26        accuracy multiclass 0.8409231 5 0.011760429 Preprocessor1_Model26\n",
       "27 27        accuracy multiclass 0.8369231 5 0.014005493 Preprocessor1_Model27\n",
       "28 28        accuracy multiclass 0.8369231 5 0.014005493 Preprocessor1_Model28\n",
       "29 29        accuracy multiclass 0.8332308 5 0.013317693 Preprocessor1_Model29\n",
       "30 30        accuracy multiclass 0.8332308 5 0.013317693 Preprocessor1_Model30\n",
       "31 31        accuracy multiclass 0.8290769 5 0.017672899 Preprocessor1_Model31\n",
       "32 32        accuracy multiclass 0.8213846 5 0.015226884 Preprocessor1_Model32\n",
       "33 33        accuracy multiclass 0.8175385 5 0.018626507 Preprocessor1_Model33\n",
       "34 34        accuracy multiclass 0.8213846 5 0.018514987 Preprocessor1_Model34\n",
       "35 35        accuracy multiclass 0.8058462 5 0.022796501 Preprocessor1_Model35\n",
       "36 36        accuracy multiclass 0.8020000 5 0.019570235 Preprocessor1_Model36\n",
       "37 37        accuracy multiclass 0.8061538 5 0.021122354 Preprocessor1_Model37\n",
       "38 38        accuracy multiclass 0.8061538 5 0.021122354 Preprocessor1_Model38\n",
       "39 39        accuracy multiclass 0.7869231 5 0.007844645 Preprocessor1_Model39\n",
       "40 40        accuracy multiclass 0.7869231 5 0.007844645 Preprocessor1_Model40"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(102)\n",
    "# Create a 5-fold cross validation object\n",
    "user_vfold <- vfold_cv(user_train, v = 5, strata = UNS)\n",
    "\n",
    "# Create a recipe for the training set and standardize the data\n",
    "user_recipe <- recipe(UNS ~ PEG, SCG, STG, LPR, STR, data = user_train) |>\n",
    "    step_scale(all_predictors()) |>\n",
    "    step_center(all_predictors())\n",
    "\n",
    "# #create a knn model specification\n",
    " knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "     set_engine(\"kknn\") |>\n",
    "     set_mode(\"classification\")\n",
    "\n",
    "# #fit the knn model into a workflow with a range of possible K values\n",
    " k_vals <- tibble(neighbors = seq (from = 1, to = 40))\n",
    "                \n",
    " knn_results <- workflow() |>\n",
    "     add_recipe(user_recipe) |>\n",
    "     add_model(knn_spec) |>\n",
    "     tune_grid(resamples = user_vfold, grid = k_vals) |>\n",
    "    collect_metrics() |>\n",
    "    filter(.metric == \"accuracy\")\n",
    "\n",
    "knn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9961618a-83da-441c-b978-1cef9b53cfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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\nBGEQQEIQBgEkBGEQQEIQBvl/dbR6nA6XhEYAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(102)\n",
    "accuracies_plot <- knn_results |>\n",
    "    ggplot( aes (y=mean, x=neighbors)) +\n",
    "    geom_point() +\n",
    "    geom_line () +\n",
    "    labs (x= \"K value\", y= \"Accuracy\") +\n",
    "    theme(text = element_text(size = 15))\n",
    "\n",
    "accuracies_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c694c4-6c66-40d5-b60a-be6344ef7352",
   "metadata": {},
   "source": [
    "From the graph, we can see that the most accurate K value is 11. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0e278550-6621-4588-b6c6-c8ed30bfc45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 40 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>neighbors</th><th scope=col>mean</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>11</td><td>0.8524615</td></tr>\n",
       "\t<tr><td>12</td><td>0.8447692</td></tr>\n",
       "\t<tr><td>15</td><td>0.8447692</td></tr>\n",
       "\t<tr><td>16</td><td>0.8447692</td></tr>\n",
       "\t<tr><td>13</td><td>0.8409231</td></tr>\n",
       "\t<tr><td>14</td><td>0.8409231</td></tr>\n",
       "\t<tr><td>17</td><td>0.8409231</td></tr>\n",
       "\t<tr><td>18</td><td>0.8409231</td></tr>\n",
       "\t<tr><td>19</td><td>0.8409231</td></tr>\n",
       "\t<tr><td>25</td><td>0.8409231</td></tr>\n",
       "\t<tr><td>26</td><td>0.8409231</td></tr>\n",
       "\t<tr><td> 9</td><td>0.8370769</td></tr>\n",
       "\t<tr><td>20</td><td>0.8369231</td></tr>\n",
       "\t<tr><td>23</td><td>0.8369231</td></tr>\n",
       "\t<tr><td>24</td><td>0.8369231</td></tr>\n",
       "\t<tr><td>27</td><td>0.8369231</td></tr>\n",
       "\t<tr><td>28</td><td>0.8369231</td></tr>\n",
       "\t<tr><td>10</td><td>0.8332308</td></tr>\n",
       "\t<tr><td>21</td><td>0.8332308</td></tr>\n",
       "\t<tr><td>29</td><td>0.8332308</td></tr>\n",
       "\t<tr><td>30</td><td>0.8332308</td></tr>\n",
       "\t<tr><td>22</td><td>0.8292308</td></tr>\n",
       "\t<tr><td> 8</td><td>0.8290769</td></tr>\n",
       "\t<tr><td>31</td><td>0.8290769</td></tr>\n",
       "\t<tr><td> 6</td><td>0.8250769</td></tr>\n",
       "\t<tr><td> 7</td><td>0.8213846</td></tr>\n",
       "\t<tr><td>32</td><td>0.8213846</td></tr>\n",
       "\t<tr><td>34</td><td>0.8213846</td></tr>\n",
       "\t<tr><td>33</td><td>0.8175385</td></tr>\n",
       "\t<tr><td>37</td><td>0.8061538</td></tr>\n",
       "\t<tr><td>38</td><td>0.8061538</td></tr>\n",
       "\t<tr><td>35</td><td>0.8058462</td></tr>\n",
       "\t<tr><td>36</td><td>0.8020000</td></tr>\n",
       "\t<tr><td> 5</td><td>0.7901538</td></tr>\n",
       "\t<tr><td>39</td><td>0.7869231</td></tr>\n",
       "\t<tr><td>40</td><td>0.7869231</td></tr>\n",
       "\t<tr><td> 4</td><td>0.7830769</td></tr>\n",
       "\t<tr><td> 3</td><td>0.7673846</td></tr>\n",
       "\t<tr><td> 1</td><td>0.7596923</td></tr>\n",
       "\t<tr><td> 2</td><td>0.7556923</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 40 × 2\n",
       "\\begin{tabular}{ll}\n",
       " neighbors & mean\\\\\n",
       " <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 11 & 0.8524615\\\\\n",
       "\t 12 & 0.8447692\\\\\n",
       "\t 15 & 0.8447692\\\\\n",
       "\t 16 & 0.8447692\\\\\n",
       "\t 13 & 0.8409231\\\\\n",
       "\t 14 & 0.8409231\\\\\n",
       "\t 17 & 0.8409231\\\\\n",
       "\t 18 & 0.8409231\\\\\n",
       "\t 19 & 0.8409231\\\\\n",
       "\t 25 & 0.8409231\\\\\n",
       "\t 26 & 0.8409231\\\\\n",
       "\t  9 & 0.8370769\\\\\n",
       "\t 20 & 0.8369231\\\\\n",
       "\t 23 & 0.8369231\\\\\n",
       "\t 24 & 0.8369231\\\\\n",
       "\t 27 & 0.8369231\\\\\n",
       "\t 28 & 0.8369231\\\\\n",
       "\t 10 & 0.8332308\\\\\n",
       "\t 21 & 0.8332308\\\\\n",
       "\t 29 & 0.8332308\\\\\n",
       "\t 30 & 0.8332308\\\\\n",
       "\t 22 & 0.8292308\\\\\n",
       "\t  8 & 0.8290769\\\\\n",
       "\t 31 & 0.8290769\\\\\n",
       "\t  6 & 0.8250769\\\\\n",
       "\t  7 & 0.8213846\\\\\n",
       "\t 32 & 0.8213846\\\\\n",
       "\t 34 & 0.8213846\\\\\n",
       "\t 33 & 0.8175385\\\\\n",
       "\t 37 & 0.8061538\\\\\n",
       "\t 38 & 0.8061538\\\\\n",
       "\t 35 & 0.8058462\\\\\n",
       "\t 36 & 0.8020000\\\\\n",
       "\t  5 & 0.7901538\\\\\n",
       "\t 39 & 0.7869231\\\\\n",
       "\t 40 & 0.7869231\\\\\n",
       "\t  4 & 0.7830769\\\\\n",
       "\t  3 & 0.7673846\\\\\n",
       "\t  1 & 0.7596923\\\\\n",
       "\t  2 & 0.7556923\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 40 × 2\n",
       "\n",
       "| neighbors &lt;int&gt; | mean &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| 11 | 0.8524615 |\n",
       "| 12 | 0.8447692 |\n",
       "| 15 | 0.8447692 |\n",
       "| 16 | 0.8447692 |\n",
       "| 13 | 0.8409231 |\n",
       "| 14 | 0.8409231 |\n",
       "| 17 | 0.8409231 |\n",
       "| 18 | 0.8409231 |\n",
       "| 19 | 0.8409231 |\n",
       "| 25 | 0.8409231 |\n",
       "| 26 | 0.8409231 |\n",
       "|  9 | 0.8370769 |\n",
       "| 20 | 0.8369231 |\n",
       "| 23 | 0.8369231 |\n",
       "| 24 | 0.8369231 |\n",
       "| 27 | 0.8369231 |\n",
       "| 28 | 0.8369231 |\n",
       "| 10 | 0.8332308 |\n",
       "| 21 | 0.8332308 |\n",
       "| 29 | 0.8332308 |\n",
       "| 30 | 0.8332308 |\n",
       "| 22 | 0.8292308 |\n",
       "|  8 | 0.8290769 |\n",
       "| 31 | 0.8290769 |\n",
       "|  6 | 0.8250769 |\n",
       "|  7 | 0.8213846 |\n",
       "| 32 | 0.8213846 |\n",
       "| 34 | 0.8213846 |\n",
       "| 33 | 0.8175385 |\n",
       "| 37 | 0.8061538 |\n",
       "| 38 | 0.8061538 |\n",
       "| 35 | 0.8058462 |\n",
       "| 36 | 0.8020000 |\n",
       "|  5 | 0.7901538 |\n",
       "| 39 | 0.7869231 |\n",
       "| 40 | 0.7869231 |\n",
       "|  4 | 0.7830769 |\n",
       "|  3 | 0.7673846 |\n",
       "|  1 | 0.7596923 |\n",
       "|  2 | 0.7556923 |\n",
       "\n"
      ],
      "text/plain": [
       "   neighbors mean     \n",
       "1  11        0.8524615\n",
       "2  12        0.8447692\n",
       "3  15        0.8447692\n",
       "4  16        0.8447692\n",
       "5  13        0.8409231\n",
       "6  14        0.8409231\n",
       "7  17        0.8409231\n",
       "8  18        0.8409231\n",
       "9  19        0.8409231\n",
       "10 25        0.8409231\n",
       "11 26        0.8409231\n",
       "12  9        0.8370769\n",
       "13 20        0.8369231\n",
       "14 23        0.8369231\n",
       "15 24        0.8369231\n",
       "16 27        0.8369231\n",
       "17 28        0.8369231\n",
       "18 10        0.8332308\n",
       "19 21        0.8332308\n",
       "20 29        0.8332308\n",
       "21 30        0.8332308\n",
       "22 22        0.8292308\n",
       "23  8        0.8290769\n",
       "24 31        0.8290769\n",
       "25  6        0.8250769\n",
       "26  7        0.8213846\n",
       "27 32        0.8213846\n",
       "28 34        0.8213846\n",
       "29 33        0.8175385\n",
       "30 37        0.8061538\n",
       "31 38        0.8061538\n",
       "32 35        0.8058462\n",
       "33 36        0.8020000\n",
       "34  5        0.7901538\n",
       "35 39        0.7869231\n",
       "36 40        0.7869231\n",
       "37  4        0.7830769\n",
       "38  3        0.7673846\n",
       "39  1        0.7596923\n",
       "40  2        0.7556923"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_accuracy <- knn_results |>\n",
    "    select(neighbors, mean) |>\n",
    "    arrange(desc(mean)) |>\n",
    "    slice\n",
    "\n",
    "knn_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5e3157-8573-416b-b0e3-0d9cd36a7cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
